- answers: '-   天辉通过分享自己在生财的经验，鼓励大家行动起来，并将分享内容授权给所有伙伴，帮助他们变现。

    -   通过天辉的分享，圈友@浅色 8ug 的喵能够通过一键转发或者小小修改的方式赚取第一桶金。

    -   《行动起来，就会有好事发生：AI 绘画万字使用手册》是天辉将当日分享的全部内容授权给了所有航海的伙伴，用于下场变现。

    -   Midjourney 基础使用手册覆盖了核心操作、绘图、模型与分辨率扩大、出图命令、出图参数等内容。

    -   天辉希望他的Midjourney基础使用手册能够带来启发，帮助更多人在AI绘画领域取得进步。'
  questions: "-   《行动起来，就会有好事发生：AI 绘画万字使用手册》作者： 天辉日期：2023-03-27\n    1.  天辉分享了生财经验，鼓励大家行动起来，分享内容授权给所有伙伴，帮助他们变现。\n\
    \    2.  通过分享，圈友@浅色 8ug 的喵开启了AI绘画之旅，赚取了第一桶金。\n    3.  天辉再次分享全文，希望能对更多圈友有所帮助或启发。\n\
    -   Midjourney 基础使用手册（万字干货文）\n    1.  天辉分享了AI绘画工具Midjourney的基础攻略，覆盖所有参数和命令的底层应用逻辑。\n\
    \    2.  目录包括核心操作、绘图、模型与分辨率扩大、出图命令、出图参数等内容。\n    3.  天辉希望这份攻略能带来启发，帮助更多人在AI绘画领域取得进步。\n\
    -   天辉是如何鼓励大家行动起来的？\n-   通过天辉的分享，圈友@浅色 8ug 能够如何赚取第一桶金？\n-   《行动起来，就会有好事发生：AI 绘画万字使用手册》是如何授权分享的？\n\
    -   Midjourney 基础使用手册覆盖了哪些内容？\n-   天辉希望他的Midjourney基础使用手册能够带来什么样的影响？"
  summary: "-   《行动起来，就会有好事发生：AI 绘画万字使用手册》作者： 天辉日期：2023-03-27\n    1.  天辉分享了生财经验，鼓励大家行动起来，分享内容授权给所有伙伴，帮助他们变现。\n\
    \    2.  通过分享，圈友@浅色 8ug 的喵开启了AI绘画之旅，赚取了第一桶金。\n    3.  天辉再次分享全文，希望能对更多圈友有所帮助或启发。\n\
    -   Midjourney 基础使用手册（万字干货文）\n    1.  天辉分享了AI绘画工具Midjourney的基础攻略，覆盖所有参数和命令的底层应用逻辑。\n\
    \    2.  目录包括核心操作、绘图、模型与分辨率扩大、出图命令、出图参数等内容。\n    3.  天辉希望这份攻略能带来启发，帮助更多人在AI绘画领域取得进步。"
  text: '# 《行动起来，就会有好事发生：AI 绘画万字使用手册》> 原文：[`www.yuque.com/for_lazy/thfiu8/xftu0r1282k5zf2n`](https://www.yuque.com/for_lazy/thfiu8/xftu0r1282k5zf2n)##
    (245 赞)《行动起来，就会有好事发生：AI 绘画万字使用手册》作者： 天辉日期：2023-03-27大家好哇，我是天辉~，「AI 绘画联盟」星球创始人，「生财有术航海家」成员，今年
    2 月份「AI 绘画&ChatGPT」航海内容出品人及教练之一。今天跟大家分享两个东东，第一部分，是帮助你行动起来的分享（航海分享）第二部分，是辅助你行动赚钱的材料（AI
    绘画万字使用手册）### 一、生财分享去年 10 月份在生财的首发帖《生财一句话，衍生一个“AI 绘图”IP》[https://articles.zsxq.com/id_jja2zeh2r7nc.html](https://articles.zsxq.com/id_jja2zeh2r7nc.html)拿到了一颗龙珠，随后专注于
    AI 绘画，在生财的帮助下不断地破圈，认识了更多圈友，帮到了更多伙伴。今年 3 月初，收到 张子安@生财有术 的邀请，我在航海中进行了《AI 绘画的新进展和未来趋势：ChatGPT
    带来的变革》的启航主题分享，内容虽然不多，但是可以鼓励伙伴们行动起来。行动起来，就会有好事发生。为了进一步降低圈友们行动的卡点，我将当天分享的全部内容授权给了所有航海的伙伴，用于下场变现。所有伙伴无论有没有基础，都可以通过一键转发或者小小修改的方式，获得第一桶金。很多圈友当天变现，拿到了正反馈，很多伙伴给我发了感谢红包。今天发帖的圈友@浅色
    8ug 的喵 通过这个行动点，开启了自己的 AI 绘画之旅，也让我非常开心~《1 年没赚回门票，2 月航海我赚了 5 倍 @浅色 8ug 的喵》[https://t.zsxq.com/0cMfh2oKR](https://t.zsxq.com/0cMfh2oKR)大家的反馈还不错，很荣幸今天再次收到子安的邀请，将当日分享的全文带给更多的圈友，希望能对大家有所帮助或启发，分享全文：[https://i.shengcaiyoushu.com/docx/UKHPdTS6jo4Dwpxn3cfcwBenngb](https://i.shengcaiyoushu.com/docx/UKHPdTS6jo4Dwpxn3cfcwBenngb)######
    二、Midjourney 基础使用手册（万字干货文）能帮得的到伙伴才是人脉，所以我也希望能够帮助到更多的伙伴，再额外分享给圈友一份 AI 绘画基础攻略，能够覆盖
    AI 绘画工具 Midjourney 目前所有的参数以及命令的底层应用逻辑。抛砖引玉，希望能够带来更多的启发，碰撞出更多的火花如果它对你有一点帮助，我会很开心，谢谢大家~####
    目录：一、核心操作1.1 出图核心1.2 付费订阅二、绘图2.1 prompt（出图用的描述词）2.2 blend（图像融合）三、模型与分辨率扩大3.1 模型（出图效果）3.2
    分辨率扩大（Upscalers）四、出图命令4.1 最全命令列表4.2 用户信息查询命令4.3 设置与预设命令（用以节省时间）4.4 复现自己历史图片命令五、出图参数5.1
    最全参数列表5.2 比例参数（--ar）5.3 稳定参数（--chaos）5.4 质量参数（--q）5.5 种子参数（--seed）'
- answers: '-   Midjourney的核心操作是通过输入描述词来生成图像。用户在聊天框里输入描述词，如“vibrant california flower”（充满活力的加利福尼亚花朵），然后按下回车，即可生成图像。

    -   Midjourney的付费订阅方式包括基础版、标准版和企业版。基础版每月10美元，适合轻度使用；标准版每月30美元，无限图片，适合重度使用；企业版每月60美元，适合重要且保密使用。如果选择年费订阅，价格可以打八折。

    -   绘图操作的基础是通过输入描述词来触发图像生成。核心操作包括：1.1 出图核心，用户通过输入描述词触发图像生成；1.2 付费订阅，用户可以根据需求选择不同的订阅版本以获得更多的使用额度。

    -   在Midjourney中，描述Prompt的基础结构包括基础Prompts和进阶Prompts。基础Prompts可以是简单的单词、短语或表情符号，而进阶Prompts可以包括图像url、文本短语和参数。

    -   进阶Prompt相比基础Prompt更加复杂，可以包含更多的信息和要求。它们需要更具体和详细的描述词，包括图像url、多个文本短语和参数，以便生成更加精确的图像。'
  questions: '-   什么是Midjourney的核心操作？

    -   Midjourney的付费订阅方式有哪些？它们之间有何区别？

    -   绘图操作的基础是什么？这些基础包括哪些内容？

    -   如何描述Midjourney中的Prompt？有哪些基础结构？

    -   进阶Prompt相比基础Prompt有何不同？需要什么样的描述词？'
  summary: "-   本文介绍了Midjourney的核心操作和付费订阅方式\n    1.  核心操作包括输入描述词生成图像和付费订阅Midjourney\n\
    \    2.  核心操作简单易懂，生成图像速度快\n    3.  付费订阅分为基础版、标准版和企业版，价格和使用范围不同\n-   绘图操作需要先了解核心操作\n\
    \    1.  Prompt是用于生成图像的文本短语\n    2.  Prompt的基础结构包括单词、短语和emoji表情\n    3.  进阶Prompt可以更复杂，需要更多的描述词"
  text: 5.6 停止参数（--stop）5.7 风格参数（--style or --s）5.8 平铺参数（--tile）5.9 版本参数（--v）5.10
    视频参数（--video）六、进阶描述词6.1 图生图进阶6.2 修图重要参数（Remix）6.3 复杂提示词（多样 prompt）七、获得免费出图时长这是一份基础教程，译自官方手册，加以我自己的经验补充。全文有一万七千字，上百张示意图。一份文章，完整度超过市面上千元的课程。写它的目的，除了帮助新手们系统入门，帮助高手们查漏补缺以外，还想以它为基础，咱们整个大的~任何文章中对你有所启发的小片段，都可以写一下你在使用过程中的经验心得。任何你觉得还能补充的地方，都可以写点补充，@我，并写上对应的章节编号。无论长短，适合的内容，我都会将你的文章链接贴在对应攻略的下方，让今后所有的后续伙伴们都能够因为你而有所得，有所启发。随着学习的伙伴越来越多，这篇文章也会越来越丰富，直到成为市面上独一无二，最大、最全、最有用的
    Midjourney 实用手册！## 一、核心操作### 1.1 出图核心聊天框输入“/imagine”描述词，会跳出一个菜单栏，选中“imagine prompt”,
    之后会跳出一个输入框，在输入框里输入文字，比如“vibrant califonia flower”(充满活力的加利福尼亚花朵)，按一下回车即可![](img/d0a8abad23ba59fafbe1d5a8d88c0ef5.png)会看到图片逐渐生成![](img/0645c37b8efc8c3c814fca94df9a98f4.png)以上就是核心操作，1
    分钟不到生成一张图，所有与 Midjourney 有关的图像生成，都离不开这一步。### 1.2 付费订阅Midjourney 免费额度很少，如果想要使用更多，需要付费订阅[https://www.midjourney.com/account/](https://www.midjourney.com/account/)基础版：10
    美元 / 月（少量图片，轻度使用）标准版：30 美元 / 月（无限图片，重度使用）企业版：60 美元 / 月（重要图片，保密使用）![](img/0741948baf535b5ee207d190d279c6ed.png)如果直接订阅年费，价格可以打八折。以上是付费订阅简单介绍，更详细的内容，参考后续章节##
    二、绘图如何到达核心操作，还不会的伙伴，可以移步飞书[https://vxcni1izs8.feishu.cn/docx/ATzUdYFxCo8QtbxMAIaceDJmnQc](https://vxcni1izs8.feishu.cn/docx/ATzUdYFxCo8QtbxMAIaceDJmnQc)接下来，我会将官方使用手册的内容解读给大家，查漏补缺，也许你会有更新的理解###
    2.1 Prompt它是一个简短的文本短语，用于生成图像。也就是你输入，让机器进行识别，并绘图的描述词。### Prompt 的组成结构#### 2.1.1
    基础 Prompts一个基础的描述词可以是简单的一个单词，短语，或者 emoji 表情比如，一只狗：a dog街道旁的大树：The big tree beside
    the street🤖(一个 emoji 表情)输入在这个聊天框里即可![](img/e665f08d0d79774dba230a288a921751.png)####
    2.1.2 进阶 Prompts
- answers: '-   图像构图、色彩和风格方面的详细信息在生成图像时非常重要。构图涉及到图像中元素的布局和相互关系，色彩则决定了图像的视觉效果和情感表达，而风格则是指整体的艺术风格或视觉风格，比如写实主义、抽象等。提供详细的描述可以帮助我们更好地理解您想要的图像效果。

    -   对于使用Prompt Text描述要生成的图像，我希望能够提供具体而清晰的描述，包括关键元素、情感或主题，并尽量避免模糊不清或含糊的描述。清晰的描述可以帮助生成的图像更准确地符合预期。

    -   在参数方面，我希望能够调整纵横比以及选择合适的模型来改变图像生成方式。纵横比的调整可以影响图像的比例和布局，而不同的模型可能会在细节展现和风格呈现上有所不同，因此选择合适的模型对我来说很重要。

    -   关于简要提示生成图像的部分，我可以提供一些更具体的例子，比如描述一个特定场景、特定对象或特定情感，并尽量提供清晰的关键词和关键要素，以便生成出符合预期的图像。

    -   当描述要的内容时，我希望您能够专注于丰富描述所需内容的细节和特点，而不是描述不需要的内容。清晰明确的描述可以帮助生成更加准确、符合预期的图像。'
  questions: '-   你能否提供一些关于图像构图、色彩和风格的详细信息，以便我们更好地生成图像？

    -   对于使用Prompt Text描述要生成的图像，你有任何特定的要求或偏好吗？

    -   在参数方面，你想要调整哪些方面以改变图像生成方式？例如，纵横比和模型的选择对你来说有多重要？

    -   关于简要提示生成图像的部分，你能否提供一些更具体的例子，以便我们更好地理解你的需求？

    -   当描述要的内容时，你希望我们专注于哪些细节来丰富描述，而不是不要的内容？'
  summary: "-   更高级的提示词可以包括一个或多个图像 url、多个文本短语和一个或多个参数\n    1.  提供图像信息，包括构图、色彩、风格等\n\
    \    2.  使用Prompt Text描述要生成的图像\n    3.  参数可以改变图像生成方式，如纵横比、模型等\n-   Prompting 简要笔记\n\
    \    1.  简短的提示可以生成图像，太长的提示可能不会表达所有元素\n    2.  对语法不敏感，但对用词敏感，使用同义词效果更好\n    3.\
    \  描述要的内容，而非不要的，多想一些细节来丰富描述"
  text: 更高级的提示词可以包括一个或多个图像 url、多个文本短语和一个或多个参数![](img/d0c373e26d846938a2f1f2b0c8de1afb.png)Image
    Prompts：（图生图，垫图，都是指这个，可以加入多个图你可以通过提供图片的方式，告诉 Midjourney 你想要生成的图像信息，包括，构图，色彩，风格，人物等信息，使用方式如下：(苹果机演示的，但网页端，电脑端都一样)![](img/9b7f78ed8b432f53e31e6d365a576e3e.png)Prompt
    Text要生成的图像的文本描述。会有一篇文章来介绍Parameters参数改变图像生成的方式。参数可以改变纵横比、模型等等非常多的影响。参数放在提示符的末尾。有固定的格式，一般是，“--对应的英文字符”，这个章节会专门写一篇文章来介绍比如--ar
    3:4   👉设置图片的纵横比为 3 比 4--v 4       👉使用第 4 版本的模型### Prompting 简要笔记#### 2.1.3 Prompt
    长度提示可以非常简单。单个单词(甚至是一个表情符号!)就可以生成一张图像。非常短的提示，那就以 Midjourney 的默认风格为主，如果想要更具体的意向场景，需要对应的提示词。然而，太长的提示也不一定更好，不是所有的图像元素都会得到表达。####
    2.1.4 语法“Midjourney”对语法、句子结构不敏感，对用词敏感。更具体的同义词在很多情况下效果更好。与其说 big，不如试着用 enormous，larger，crucial，important，considerable，material。与大家理解的越大越全不同，实际上，单词越少，每个单词的影响力就越大。用逗号分割语义，如果想让某些元素组合表达，用括号或者连字符以及
    and , with , of 等词汇进行结合。#### 2.1.5 表达要的，而非表达不要的最好描述你想要什么，而不是你不想要什么。如果你要求一个“没有蛋糕”的派对，你的形象可能会包括一个蛋糕。如果要去除元素，可以参考
    --no 参数，具体使用方式，后续会说。#### 2.1.6 多想一点细节一个反常规的思路：描述词不是描述词，而是限定词，你所限定的内容，由 Midjourney
    理解并体会表达。你所不限定的，它将自由发挥。自由发挥的内容可能很好，也可能很差，所以，如果你已经有比较好的细节想法，多想一想，把它描述出来一些简单的细节参考思路示例：主题：person,
    animal, character, location, object, etc.（人物、动物、人物、地点、物体等）媒介：photo, painting,
    illustration, sculpture, doodle, tapestry, etc（照片、绘画、插画、雕塑、涂鸦、挂毯等）环境： indoors,
    outdoors, on the moon, in Narnia, underwater, the Emerald City, etc.（室内、室外、月球上、纳尼亚、水下、翡翠城等）灯光：soft,
    ambient, overcast, neon, studio lights, etc（柔和，环境，阴天，霓虹灯，工作室灯等）颜色：vibrant, muted,
    bright, monochromatic, colorful, black and white, pastel, etc.（鲜艳、柔和、明亮、单色、彩色、黑白、粉彩等）情绪：
- answers: "-   如何使用数量词和修饰词来增强图像的具体性和感知效果？\n    -   使用精确的数量词和具体的修饰词可以帮助增强图像的细节和感知效果，比如指定“three\
    \ cats”而不是“cats”，使用词汇如enormous、larger、crucial等来描述物体的大小，以及使用诸如soft、ambient、vibrant等词汇来描述颜色和情感。\n\
    -   Blend功能有哪些限制？如何确保融合效果良好？\n    -   Blend功能能够无需描述词，直接将2~5张图融合在一起产生新图像。然而，它存在一些限制，例如无法在融合的基础上加入文字描述词，并且融合的两张图最好保持比例一致。为确保融合效果良好，可以注意选择融合的图片，保持比例一致，并在必要时进行微调。\n\
    -   不同的时代、表情、颜色和环境如何影响图像的风格和模式？\n    -   不同的时代、表情、颜色和环境会直接影响图像的风格和模式。例如，时代不同会有不同的视觉风格，表情会赋予角色个性，颜色会赋予图像不同的风格，环境变化也会导致图像呈现不同的模式。\n\
    -   不同版本的模型（例如v1-v5、Niji、Test）有何区别？它们如何影响图像生成的效果？\n    -   不同版本的模型具有不同的特点和影响。例如，v1-v5模型中，数字越高代表升级版，Niji模型适用于动漫风格，Test模型用于临时测试和反馈。这些模型的不同版本会影响图像生成的效果，包括解释自然语言提示的能力、分辨率以及对不同类型提示的理解能力。\n\
    -   v5模型相对于其他模型有什么特别之处？\n    -   v5模型相对于其他模型具有更高的一致性，擅长解释自然语言提示，并且具有更高的分辨率。"
  questions: '-   如何使用数量词和修饰词来增强图像的具体性和感知效果？

    -   Blend功能有哪些限制？如何确保融合效果良好？

    -   不同的时代、表情、颜色和环境如何影响图像的风格和模式？

    -   不同版本的模型（例如v1-v5、Niji、Test）有何区别？它们如何影响图像生成的效果？

    -   v5模型相对于其他模型有什么特别之处？'
  summary: "-   描述图像的具体数量词和修饰词对于创作更具象的效果至关重要\n    1.  数量词如“three cats”比“cats”更具体\n\
    \    2.  修饰词如艺术媒介和描述词有助于创造正确外观和感觉的图像\n    3.  不同的时代、表情、颜色和环境会影响图像的风格和模式\n-   Blend功能介绍\n\
    \    1.  Blend是将多张图融合产生新图像的方式\n    2.  融合效果好，但不能加入文字描述词或超过5张图\n    3.  使用“/blend”命令上传图片进行融合，保持融合图比例一致\n\
    -   模型与分辨率扩大\n    1.  不同模型如v1-v5、Niji、Test等具有不同升级版效果\n    2.  在描述词后加上对应后缀使用不同模型\n\
    \    3.  v5模型擅长解释自然语言提示，展示高一致性效果"
  text: Sedate, calm, raucous, energetic, etc.（稳重、冷静、沙哑、精力充沛等）构图：Portrait, headshot,
    closeup, birds-eye view, etc.（人像、大头照、特写、鸟瞰图等）#### 2.1.7 具体的数量词，而非含糊的量词“three cats”（3
    只猫）要比“cats”（猫们）效果更具象，“a flock of birds”（一群鸟）要比“birds”（鸟们）效果更具象。2.1.8 一些修饰词示例简短的单词提示，也会在
    Midjourney 的默认风格中产生很棒的效果但也有很多的修饰词，对画面影响很大比如，想要生成一只猫，有多少种不同的猫#### 2.1.8.1 艺术介质颜料？蜡笔？刮板？印刷机？亮片？墨水？彩纸？......产生时尚形象的最好方法之一，是指定一种艺术媒介。![](img/260f437b411ee5535105315beff93a88.png)![](img/720e224f79d11e785ac9e17f44cbbfb2.png)####
    2.1.8.2 精确描述更精确的单词和短语将有助于创建具有正确外观和感觉的图像。![](img/5d166f15b421ebef15f01c62238f30cf.png)####
    2.1.8.3 时间旅行者不同的时代有不同的视觉风格![](img/3a364691c8630a101f820a16ceb9c1a3.png)![](img/c5024fc1553cab3fa23b4ae4abbfb4ad.png)####
    2.1.8.4 表情使用情感词汇赋予角色个性![](img/ab380e1464a23415548d2b8ed5512d74.png)#### 2.1.8.5
    颜色化使用不同的颜色赋予风格![](img/7489f9c51bcd4f8c80f7defa1abc7e98.png)![](img/5fc54c0326a3ac39497c0f30aaa04d6f.png)####
    2.1.8.6 环境变化不同的环境会出现不同的模式![](img/26186a1038da538badf2fe6c0e648ed5.png)以上是一些介绍，帮助大家理解，还有更多修饰词###
    2.2 Blend2.2.1 介绍Blend 功能，是无需描述词，直接将 2 ~ 5 张图融合在一起产生新图像的方式。它融合图片效果很好，但是不能在图的基础上加入文字描述词如果想加描述词，或者融合超过
    5 张图，参考 2.1.1 章节的垫图部分为了效果好，融合的两张图，比例最好保持一致2.2.2 使用方式输入“/blend”，再从跳出的框中选择 blend，随后，按提示上传图片进行融合，最后按发送，开始生成图像![](img/8f2a63c172e307eaa22fdef928eb9cd2.png)2.2.3
    图像比例可以点“more”来找到“dimensons”, 改变图像纵横比![](img/cedcea64e48c534a0b74dbd9f8dc4c91.png)##
    三、模型与分辨率扩大### 3.1 模型目前，有 1，2，3，4，5（数字越高，越是是升级版），Niji（动漫），Test，Testp 几个模型使用方式：在对应的描述词后，加上对应的后缀--v
    1--v 2--v 3--v 4--v 5--niji--test--testp效果展示：3.1.1 v5 模型--v 5 模型，该模型具有非常高的一致性，擅长解释自然语言提示，
- answers: '-   Midjourney 的默认模型是 v4 模型，有三个版本：4a、4b、4c。它们的区别在于处理小细节方面的能力和对复杂提示的处理方式不同。

    -   Midjourney 提供了旧模型 v1、v2、v3 和 hd。它们在处理图像方面有所不同，比如，v1、v2、v3 是早期版本，而 hd 则可能具有更高的分辨率和更多的细节。

    -   动漫模型 nijiniji 是 Midjourney 和 Spellbrush 合作的产物，专门用于处理动漫风格的图像和插图。它对动漫、动漫风格和动漫美学有更深入的理解，擅长表现动态和动作镜头，以及以人物为中心的构图。

    -   Midjourney 的测试模型包括 test 和 testp。它们用于临时发布新模型以进行社区测试和反馈。testp 比 test 更加写实，可以提供更多样化的图像。

    -   Midjourney 的分辨率扩大功能通过不同的按钮来实现，包括默认的 U 增加分辨率按钮（U1、U2、U3、U4）、Light Upscale、Beta
    Upscale、Upscale to Maxv1、v2、v3、hd 和针对动漫模型 niji 的 U 增加分辨率按钮（U1、U2、U3、U4 或者参数 --upanime）。这些按钮可以平滑地增加细节和纹理，或者将图像放大以增加更多的细节。'
  questions: '-   什么是 Midjourney 的默认模型？有哪些版本？它们的区别是什么？

    -   Midjourney 提供了哪些旧模型？它们分别有什么特点？

    -   介绍一下动漫模型 nijiniji，它在处理动漫方面有何特点？

    -   Midjourney 的测试模型有哪些？它们用于什么目的？有什么区别？

    -   Midjourney 中的分辨率扩大功能是如何工作的？有哪些按钮可以用来增加分辨率和细节？'
  summary: "-   具有更高的分辨率![](img/651a7a19da772d193b3af3a671a58269.png)3.1.2 v4 模型--v\
    \ 4 模型是 Midjourney 的默认模型，具有更多知识，处理细节更好，可处理复杂提示。分为4a，4b，4c版本，使用方式有差别。![](img/dc60f3fddcc3b71fccf5b2180d8ba6e0.png)旧模型\
    \ v1，v2，v3，hd![](img/c65d71e7c5fcc3418f26f5b8fe853a8a.png)![](img/495858d1fc124d6ac477dcb058c08094.png)动漫模型\
    \ nijiniji 用于动画和插图风格，对动漫有更多了解，表现出色。![](img/42daed7b93d72e3f2f2344670d03a246.png)![](img/479f718d2ec12c3b30136aa8f3172a8d.png)\n\
    \    1.  v4 模型是默认模型，处理细节更好，可处理复杂提示。\n    2.  旧模型包括 v1，v2，v3，hd，有不同特点。\n    3.\
    \  动漫模型 nijiniji 对动漫有更多了解，表现出色。\n-   3.1.5 测试模型 Test偶尔会临时发布新模型以进行社区测试和反馈。旧的有两个可用的测试模型:test\
    \ 和 testp，它们可以与 --creative 参数结合使用，以获得更多样化的组合。更风格化的 test![](img/b61e46697e0b1279ec461f486c81f9cb.png)更写实的\
    \ Testp![](img/0f3def540041b07796640fbaf588c602.png)3.1.6 怎么转换模型？只要在描述词后，追加对应的后缀即可![](img/45f707826c74407fc028a853f717f671.png)也可以使用/settings\
    \ 命令（具体见后文的命令章节）1️⃣ MJ Version 1 2️⃣ MJ Version 2 3️⃣ MJ Version 3 4️⃣ MJ Version\
    \ 4 \U0001F308 Niji Mode \U0001F916MJ Test \U0001F4F7 MJ Test Photo\n    1.  测试模型\
    \ Test 用于社区测试和反馈，有 test 和 testp 两个版本。\n    2.  可在描述词后追加后缀或使用/settings命令转换模型。\n\
    \    3.  提供多种模型选择，包括 MJ Version 和 Niji Mode。\n-   3.2 分辨率扩大Midjourney 首先为每个任务生成一个低分辨率图像选项网格。可以之后通过按钮，添加额外的细节。不同的按钮，增加分辨率，添加细节的方式不同。（U1，U2，U3，U4，代表放大对应位置图片的分辨率）（V1，V2，V3，V4，代表以对应图片为基础，再分别生成\
    \ 4 张图）![](img/05fb209b1f689271e7179ef8c402be6e.png)点过 U 之后的图像，出现新的放大按钮如下：![](img/9adcef55183d814e9944c37b0619dfe0.png)各放大分辨率一览表（在图像默认比为\
    \ 1:1 的前提下）：从左到右，代表放大前后![](img/d827ee507861b16c5dd8d104df3085e5.png)3.2.1 默认的\
    \ U 增加分辨率（U1,U2,U3,U4）平滑地增加细节，增加图像大小。\n    1.  Midjourney 生成低分辨率图像选项网格，可通过按钮添加细节。\n\
    \    2.  不同按钮增加分辨率和细节的方式不同，如 U1，U2，U3，U4。\n    3.  默认的 U 增加分辨率平滑地增加细节，增加图像大小。"
  text: 具有更高的分辨率![](img/651a7a19da772d193b3af3a671a58269.png)3.1.2 v4 模型--v 4 模型：Midjourney
    当前的默认模型，也就是不加后缀的前提下，会默认使用。有更多的生物、地点、物体等知识。它在处理小细节方面做得更好，可以处理包含多个字符或对象的复杂提示。![](img/dc60f3fddcc3b71fccf5b2180d8ba6e0.png)它分为三个版本，4a，4b，4c，有一些细微的差别使用方式：描述词后缀加--style
    4a--style 4b--style 4c（这个其实就是--v 4）差别演示：![](img/9f066ba9bb52ec7710aac36eb203624b.png)![](img/1227448f6338742cdc5c8a552aa72f31.png)3.1.3
    旧模型 v1，v2，v3，hd![](img/c65d71e7c5fcc3418f26f5b8fe853a8a.png)![](img/495858d1fc124d6ac477dcb058c08094.png)3.1.4
    动漫模型 nijiniji 模型是 Midjourney 和 Spellbrush 之间的合作，用于制作动画和插图风格。它对动漫、动漫风格和动漫美学有更多的了解，在动态和动作镜头以及以人物为中心的构图方面表现出色。![](img/42daed7b93d72e3f2f2344670d03a246.png)![](img/479f718d2ec12c3b30136aa8f3172a8d.png)3.1.5
    测试模型 Test偶尔会临时发布新模型以进行社区测试和反馈。旧的有两个可用的测试模型:test 和 testp，它们可以与 --creative 参数结合使用，以获得更多样化的组合。更风格化的
    test![](img/b61e46697e0b1279ec461f486c81f9cb.png)更写实的 Testp![](img/0f3def540041b07796640fbaf588c602.png)3.1.6
    怎么转换模型？只要在描述词后，追加对应的后缀即可![](img/45f707826c74407fc028a853f717f671.png)也可以使用/settings
    命令（具体见后文的命令章节）1️⃣ MJ Version 1 2️⃣ MJ Version 2 3️⃣ MJ Version 3 4️⃣ MJ Version
    4 🌈 Niji Mode 🤖MJ Test 📷 MJ Test Photo### 3.2 分辨率扩大Midjourney 首先为每个任务生成一个低分辨率图像选项网格。可以之后通过按钮，添加额外的细节。不同的按钮，增加分辨率，添加细节的方式不同。（U1，U2，U3，U4，代表放大对应位置图片的分辨率）（V1，V2，V3，V4，代表以对应图片为基础，再分别生成
    4 张图）![](img/05fb209b1f689271e7179ef8c402be6e.png)点过 U 之后的图像，出现新的放大按钮如下：![](img/9adcef55183d814e9944c37b0619dfe0.png)各放大分辨率一览表（在图像默认比为
    1:1 的前提下）：从左到右，代表放大前后![](img/d827ee507861b16c5dd8d104df3085e5.png)3.2.1 默认的 U
    增加分辨率（U1,U2,U3,U4）平滑地增加细节，增加图像大小。
- answers: '-   如何区分网格图像升级工具中的不同放大选项？

    -   可以通过不同按钮来区分不同放大选项，如U1、U2、U3、U4代表默认的放大选项，Light Upscale和Beta Upscale代表少量细节与纹理的放大，以及适合面部和光滑表面的放大，而Upscale
    to Max仅适用于v1、v2、v3、hd模型，放大更多细节。

    -   Niji模型的主要特点是什么？它如何与其他放大选项区别开来？

    -   Niji模型主要用于动画和插图风格，对动漫、动漫风格和动漫美学有更深的理解。它在动态和动作镜头以及以人物为中心的构图方面表现出色。与其他放大选项相比，Niji模型更适合处理动漫风格的图像，并且在插图和动漫风格方面表现更佳。

    -   出图命令中的主要功能有哪些？它们如何根据需求进行选择和使用？

    -   出图命令的主要功能包括/imagine用于生成图像、/blend用于融合图片、/faq用于快捷获得问答等。根据需求，可以选择不同的功能来实现不同的目标，比如需要生成图像则使用/imagine，需要融合图片则使用/blend。

    -   Light Upscale、Beta Upscale和Upscale to Max这三种放大选项各适用于哪些情况？它们之间的主要区别是什么？

    -   Light Upscale适用于少量细节与纹理的放大，适合一些轻微的细节处理；Beta Upscale适用于面部和光滑表面的放大，更加适合一些需要保持平滑的表面；而Upscale
    to Max则适用于需要放大更多细节的情况，但仅适用于v1、v2、v3、hd模型。它们之间的主要区别在于应用场景和放大的细节程度。

    -   Niji模型的Remaster功能是如何工作的？它如何提供对旧版本图片的升级？

    -   Niji模型的Remaster功能通过使用--test和--creative参数，将原始图像的组成和更新的--test模型的一致性混合，再次升级图像。这样可以利用新模型的知识和技能对旧版本图片进行重新塑造和提升，使其具有更高的质量和更多的细节。'
  questions: '-   如何区分网格图像升级工具中的不同放大选项？

    -   Niji模型的主要特点是什么？它如何与其他放大选项区别开来？

    -   出图命令中的主要功能有哪些？它们如何根据需求进行选择和使用？

    -   Light Upscale、Beta Upscale和Upscale to Max这三种放大选项各适用于哪些情况？它们之间的主要区别是什么？

    -   Niji模型的Remaster功能是如何工作的？它如何提供对旧版本图片的升级？'
  summary: "-   网格图像升级工具包含多种放大选项，如Light Upscale和Beta Upscale，适用于不同细节需求。\n    1.  Light\
    \ Upscale适合少量细节和纹理的放大。\n    2.  Beta Upscale适合面部和光滑表面的放大。\n    3.  Upscale to\
    \ Max适合增加更多细节的放大。\n-   Niji模型提供动漫风格的放大选项，适合插图和动漫风格的使用。\n    1.  Niji模型默认的U增加分辨率，生成四张图的放大。\n\
    \    2.  Remaster是对旧版本图片进行新模型重塑的附加按钮，混合原始图像和更新的模型进行再次升级。\n-   出图命令包括多种功能，如查询问题、融合图片、查看主题通知等，可根据需求选择不同命令。\n\
    \    1.  /ask用于查询问题。\n    2.  /blend用于融合图片。\n    3.  /daily_theme用于查看每日主题通知。"
  text: 一些小的元素可能会在初始网格图像和完成的升级之间发生变化。使用方式：按钮 U1，U2，U3，U4![](img/de91a0ef94c0e0430af6037232750b58.png)3.2.2
    Light Upscale少量细节与纹理的放大（也可用于减少细节的使用）使用方式：按钮 Light Upscale Redo，或者描述词后缀添加 --uplight![](img/52a6dded98c7cad2a871d62e55ab57ad.png)3.2.3
    Beta Upscale没有太多额外的细节，比较适合面部和光滑表面的放大。使用方式：按钮 Beta Upscale Redo，或者描述词后缀添加 --upbeta![](img/52a6dded98c7cad2a871d62e55ab57ad.png)3.2.4
    Upscale to Maxv1，v2，v3，hd 模型时期的按钮，会将图片放大增加更多的细节，其他模型不适用![](img/a9623c1c9a83616d30f487cbca0ffe8b.png)3.2.5
    Niji 模型默认的 U 增加分辨率（U1,U2,U3,U4）同 3.2.1，区别是，它是动漫模型 --niji 生成的四张图的放大，经过优化，可以很好地使用插图和动漫风格使用方式：按钮
    U1，U2，U3，U4 或者参数 --upanime3.2.6 Remaster（理解为旧版本图片的新模型重塑即可）是先前使用 v1、v2 或 v3 模型版本，制作的放大图像的附加按钮。Remaster
    将使用 --test 和 --creative 参数将原始图像的组成和更新的 --test 模型的一致性混合，再次升级图像![](img/5a01689a364f805f89f0be7b8f73c994.png)（右为重塑后的图像）##
    四、出图命令### 4.1 最全命令列表命令，是指在聊天框中输入“/+英文字符”，在出来的菜单栏选中后，点击发送调出相应功能的方式最熟悉的，是绘图命令“/imagine”![](img/d0a8abad23ba59fafbe1d5a8d88c0ef5.png)其实，还有更多的命令，有不同的功能，标蓝色的是常用命令，按照首字母排序4.1.1###
    /ask可以用来查询问题4.1.2### /blend融合图片4.1.3### /daily_theme查看每日主题通知4.1.4### /docs查找官方使用手册内容（此命令需要频道内有Charon
    the FAQ Bot机器人）如果不知道怎么添加，就去 Midjourney 官方频道发送指令就好了4.1.5### /faq快捷获得问答4.1.6###
    /fast转换为，fast 出图模式（之后会说明这是啥）4.1.7### /help获取一些帮助信息4.1.8### /imagine生成图像的核心4.1.9###
    /info获取账户信息，比如，还有多久的出图时长等4.1.10### /stealth转换为，私密出图模式，你出的图片，不会被别人搜索到描述词4.1.11###
    /public转换为，公开出图模式，你出的图片，会被别人在画廊搜索到描述词4.1.12### /subscribe获得付费订阅的链接4.1.13### /settings查看默认设置4.1.14###
    /prefer option创建一些自己想要的喜好描述词组合参数4.1.15### /prefer option list查看自己的描述词组合清单4.1.16###
    /prefer suffix
- answers: '-   如何在复现图像时添加描述词的默认后缀？

    -   可以使用命令 `/prefer suffix` 后接需要添加的默认后缀，例如 `/prefer suffix --uplight --video`，这样在复现图像时会自动添加指定的后缀。

    -   用户如何进行基础信息查询？

    -   用户可以使用命令 `/info` 进行基础信息查询，这会显示当前排队和正在运行的作业、订阅类型、更新日期等信息。

    -   付费订阅查询的流程是怎样的？

    -   用户可以使用命令 `/subscribe` 查询付费订阅情况，该命令会显示当前付费订阅的情况以及用来订阅的相关信息。

    -   如何将图像转换为 relax 出图模式？

    -   用户可以使用命令 `/relax` 将图像转换为 relax 出图模式，这样就可以利用 Midjourney 的闲置服务器资源来生成图片，不受时长限制。

    -   用户如何设置出图工作模式以及确定图像是否公开可见？

    -   出图工作模式可以通过命令 `/settings` 进行设置，根据个人需求选择 fast 或 relax 模式。确定图像是否公开可见可以使用命令 `/public`
    和 `/stealth`，前者会使生成的图片可以被别人在画廊搜索到，而后者则会保持图片的隐私性，不被他人搜索到。'
  questions: '-   如何在复现图像时添加描述词的默认后缀？

    -   用户如何进行基础信息查询？

    -   付费订阅查询的流程是怎样的？

    -   如何将图像转换为 relax 出图模式？

    -   用户如何设置出图工作模式以及确定图像是否公开可见？'
  summary: "-   每个描述词后加个默认后缀，可通过 Job ID 复现图像，转换为 relax 出图模式，或开启修饰模式。\n    1.  描述词后加默认后缀\n\
    \    2.  使用 Job ID 复现图像\n    3.  转换为 relax 出图模式\n-   用户信息查询命令包括基础信息查询和付费订阅查询，以及出图工作模式和是否公开可见。\n\
    \    1.  基础信息查询\n    2.  付费订阅查询\n    3.  出图工作模式和是否公开可见\n-   设置与预设包括默认选项更改和自定义参数集，可快捷更改默认选项和创建自定义选项。\n\
    \    1.  默认选项更改\n    2.  自定义参数集\n    3.  创建自定义选项和管理"
  text: 每个描述词后加个默认后缀4.1.17### /show用 Job ID 来复现图像4.1.18### /relax转换为，relax 出图模式4.1.19###
    /remix开启修饰模式### 4.2 用户信息查询命令#### 4.2.1 基础信息查询（/info）查看有关当前排队和正在运行的作业、订阅类型、更新日期等的信息。动图演示：![](img/a402bdf2723388c46be5527968f9677e.png)静态展示：![](img/e2ebc4ababda6604109c426af0c281ec.png)会显示现在的使用时长等信息，比如这张图，还有
    14.98h 的 fast 模式使用时长4.2.2 付费订阅及查询（/subscribe）查看目前付费订阅情况，以及用来订阅#### 4.2.3 出图工作模式（/fast
    和 /relax）/fast 模式，是 Midjourney 出图的基础剩余时长，也会优先调用其后端资源。通俗理解，就是更快地生成图片，但是每个月有时长限制，使用结束后，就无法再生成/relax
    模式，使用 Midjourney 闲置服务器资源来生成图片，不限制时长，所以可以无限出图片。平时速度差别不大，使用人数过多时，卡顿比较明显。（只有付费的标准版和企业版可用）####
    4.2.4 是否公开可见（/public 和 /stealth）每个人的图片，都可以在画廊被人搜索到使用的描述词如果不想被被人搜索到，想要保密描述词资源，就要转换为/stealth
    模式### 4.3 设置与预设#### 4.3.1 默认选项更改（/settings）很多时候，每次都手动进行更改，太慢了，这个指令可以快捷更改默认选项![](img/fce1591979acd444f2e055f35a802f2c.png)按钮变成绿色，就表示，接下来，无需每次进行命令或者参数调整，都默认选中按钮所示的功能![](img/15b95ca41fd2151c7462084a4b6d77cf.png)1，2，3，4，5，niji，MJ
    Test，MJ Test Photo，就代表着之前所述的模型，选中之后，无需使用--v 4 等参数，默认你使用该参数其他按钮同理，其对应参数关系如下：![](img/d05969446bdd810046c4db1af64bfbe2.png)![](img/8a94d2db77b2dfbcb0ab43612691e5e0.png)![](img/7af15a8af533c0bd21491766cfa4ab63.png)![](img/3d35ae6e3926fdf2b6dad826247d739f.png)![](img/c588416ae857a9816e96255481e3712a.png)![](img/daf88d005cef5a4a28ebc90c5a4fd089.png)4.3.2
    自定义参数集（/prefer 系列）使用 prefer 命令创建自定义选项，自动将常用参数添加到提示符的末尾。/prefer auto_dm      已完成的作业将自动发送到“直接消息”/prefer
    option 创建或管理自定义选项/prefer option list 查看当前自定义选项。/prefer suffix 指定要添加到每个提示符末尾的后缀。4.3.2.1
    Prefer Option/prefer option set <name> <value>创建一个自定义参数，可以使用它在快速提示的末尾添加多个参数。
- answers: '-   自定义参数设置和删除可以通过使用`/prefer option set <name> <value>`来创建一个自定义参数，而要删除自定义参数，则可以使用相同的设置，但将`<value>`部分删除，然后发送即可。

    -   Prefer Suffix功能会自动在所有描述词后添加指定的后缀。你可以使用`/prefer suffix`命令，后接要添加到每个描述词末尾的后缀。比如：`/prefer
    suffix --uplight --video`。

    -   要查看自定义参数的含义列表，可以使用`/prefer option list`命令。发送该命令后，系统会展示目前所有自定义参数所代表的含义列表。

    -   要复现历史图片，首先需要找到历史图片的Job_ID。这可以通过个人主页、图片链接或者文件名来获取。然后，使用复现命令，并提供找到的Job_ID即可。

    -   你可以从个人主页、图片链接或者文件名中找到历史图片的Job_ID。无论是从个人主页、图片链接还是文件名，你都需要找到那一串长字符，这就是Job_ID。'
  questions: '-   如何进行自定义参数设置和删除？

    -   Prefer Suffix功能是如何工作的？

    -   如何查看自定义参数的含义列表？

    -   复现历史图片的关键步骤是什么？

    -   从哪里可以找到历史图片的Job_ID？'
  summary: "-   操作指南：自定义参数设置和删除\n    1.  点击发送后，相当于创建了一个新参数\n    2.  输入相同设置删除自定义参数\n\
    \    3.  使用/prefer option list查看自定义参数含义列表\n-   Prefer Suffix功能介绍\n    1.  自动在描述词后添加指定后缀\n\
    \    2.  只有参数可以设置后缀，其他文字不行\n    3.  示例：/prefer suffix --uplight --video\n-   复现历史图片功能说明\n\
    \    1.  找到历史生成图片进行后续处理\n    2.  关键在于找到历史图片的Job_ID\n    3.  从个人主页、图片链接或文件名寻找Job_ID"
  text: '![](img/9967b56a3bab292e3af0c731a39af3c8.png)比如，按照如上设置，点击发送后，就相当于用/prefer
    option setmine--hd --ar 7:4创建了一个“--mine”参数，“--mine”的效果，等于“--hd --ar 7:4”（当然，只是一个示例，现在--hd
    已经是过时的参数，7 比 4 的图像也不适应现在的新模型，但原理是相通的）![](img/be16efdbc3648d631ddf66981b316e7b.png)注：如果想要删除自定义参数，那就输入同样的设置，把
    value 后面的内容都删去，点击发送即可/prefer option list 点击发送，展示目前自定义的参数代表的含义列表![](img/be16efdbc3648d631ddf66981b316e7b.png)####
    4.3.2.2 Prefer Suffix/prefer suffix 自动在所有描述词后添加指定后缀比如：  /prefer suffix --uplight
    --video注意：只有参数可以这样设置，其他文字不行，也就是 --uplight 等可以，a dog，a cat 等词汇不行### 4.4 复现自己的历史图片（Show）这个功能，可以让你找到你的历史生成图片，然后继续进行后续处理（为什么要找它，因为后期图片多了，很难找到自己当时处理的界面，这样就可以再处理了）关键在于找到你的历史图片的
    Job_ID 一长串的字符（只有自己生成的图才可以用这个命令，别人的不行）使用示例：![](img/c5d3a37f67fa4166b96c9fc0226fc3ae.png)4.4.1
    从个人主页寻找[https://www.midjourney.com/app/](https://www.midjourney.com/app/)（你的用户主页）![](img/62a9397a118ac80a1132ebb999b11c7b.png)![](img/bdf042f24ff2f0e98f7c523e5acc0992.png)4.4.2
    从图片链接寻找比如，自己的图片网址 URL 是[https://www.midjourney.com/app/users/381590592095911946/?jobId=](https://www.midjourney.com/app/users/381590592095911946?jobId=)9333dcd0-681e-4840-a29c-801e502ae424.那么绿色的部分，就是
    Job_ID![](img/0b5ccecb14a92dd9332c4aa433e4a6e9.png)4.4.3 从文件名寻找如果你下载的图片，有相应的信息，可以复制![](img/83d06ae6e2f7e5873c6d0b0165e46224.png)4.4.4
    用 Discord 的 emoji 表情找发送一个📧反应贴在图片下方，则机器人会发给你对应的图片信息如何发送📧，参照以下图片👇![](img/7d3fba8441e0ee7be299e8bbd2ae6361.png)Job_ID在这里👇![](img/c1f6619cdc7cf49dd80af7f2a7b7e145.png)如果你找不到上图右边的信息，那么，它在这里![](img/9d60620748f0d97bf35293a0f15b2c03.png)##
    五、出图参数### 5.1 最全参数列表现在，来说说，'
- answers: '-   调整图片生成时，影响图像的纵横比的参数是--ar或--aspect。一些常见的纵横比例子包括：

    -   在深度学习模型中，chaos参数影响生成结果的多样性。数字越高，生成的图片结果会更不寻常、更意想不到，具有更多的变化和变异性。

    -   在使用图片生成模型时，可以利用no参数去除不想要的图片元素描述。例如，使用--no yellow可以去除图片中的黄色元素描述，适用于用户希望排除黄色调的场景。

    -   v4和v5模型的默认参数及可变范围有所不同。v4模型默认参数为--version 4，而v5模型默认参数为--version 5。它们在生成图像时的性能和效果上可能存在差异，v5模型可能具有更高的效率和更好的图像质量。

    -   在选择深度学习模型参数时，关键方面包括纵横比、混乱程度、质量、种子、停止数等。建议根据所需的图像风格和效果来调整参数，同时可以尝试不同的参数组合以获得最佳结果。'
  questions: '-   在调整图片生成时，哪些参数会影响图像的纵横比？能否提供一些常见的纵横比例子，并说明它们适合的平台？

    -   深度学习模型中的chaos参数如何影响生成结果的多样性？数字越高会导致怎样的图片结果？

    -   在使用图片生成模型时，如何利用no参数去除不想要的图片元素描述？能否举例说明一种典型的使用情况？

    -   v4和v5模型的默认参数及可变范围有何不同？它们在生成图像时的性能和效果有何区别？

    -   深度学习模型参数的介绍中，有哪些关键方面需要考虑？在选择合适的参数时，有何建议或指导原则？'
  summary: "-   参数部分包括了影响图片生成的重要参数，如ar、chaos、no、q、seed等\n    1.  ar参数可以改变图像的纵横比，如适合小红书的3:4和抖音的9:16\n\
    \    2.  chaos参数可以改变结果的多样性，数字越高产生的图片越不同寻常\n    3.  no参数可以去除不想要的图片元素描述，如no yellow表示不要黄色\n\
    -   模型参数包括了v4和v5模型的默认参数和可变范围\n    1.  v4模型默认参数和可变范围\n    2.  v5模型默认参数和可变范围\n \
    \   3.  模型参数的介绍"
  text: 很重要的，影响图片生成的，参数部分（橘黄色区域）![](img/d0c373e26d846938a2f1f2b0c8de1afb.png)现行参数：--ar,
    --chaos, --no, --q, --seed, --stop, --style, --stylize, --uplight, --upbeta, --niji,
    --hd, --test, --testp, --v, --creative, --iw, --sameseed, --video弃用，过时参数：--width
    and --w (被 --ar 替代)，--height and --h (被 --ar 替代)，--fast (被 --quality 替代)，--vibe，--hq，--newclip，--nostretch，--old，--beta####
    5.1.1 基础参数####### 5.1.1.1 Aspect Ratios--aspect or --ar改变图像的纵横比比如，适合小红书的用 --ar
    3:4适合在抖音的用 --ar 9:16#### 5.1.1.2 Chaos--chaos <数字 0–100>改变结果的多样性。更高的数值会产生更不同寻常和意想不到的图片。比如：--chaos
    4--chaos 99#### 5.1.1.3 No--no 后面接不想图片产生的元素描述，会进行去除--no yellow（不要黄色这个色彩）#### 5.1.1.4
    Quality--quality <.25, .5, 1, or 2>, or --q <.25, .5, 1, or 2>图片质量等级，比如，--q 0.25
    （四分之一质量）--q 2（两倍质量）#### 5.1.1.5 Seed--seed <integer between 0–4294967295>Midjourney
    机器人使用一个种子号来创建一个视觉噪声场，就像电视静态一样，作为生成初始图像网格的起点。种子号是为每个图像随机生成的，但可以使用 --seed 或 --sameseed
    参数指定。使用相同的种子号和提示符将产生类似的结果图像。比如，--seed 25252322#### 5.1.1.6 Chaos--stop <integer
    between 10–100>使迭代步数停留在早期，也就是你看到图像正在生成时，中途停止数字越靠前，图像生成停止越提前比如，--stop 40#### 5.1.1.7
    Style--style <4a, 4b or 4c>转换模型为 4a，4b 或 4c比如--style 4b#### 5.1.1.8 Stylize--stylize
    <number>, or --s <number>参数影响了 Midjourney 的默认美学风格在图像生成上的应用程度，数字越高，越风格化比如，--s 480####
    5.1.1.9 Uplight--uplight放大后的图像细节更少，更平滑，参照本文3.2.2#### 5.1.1.10 Upbeta--upbeta结果更接近原始网格图像，放大后的图像添加的细节明显更少，参照本文3.2.3####
    v4 模型默认参数，以及参数可变范围![](img/2562a02a0da64804f89e4461a141c448.png)#### v5 模型默认参数，以及参数可变范围![](img/d97938eb0a7644dc89028f0c0dad29a0.png)####
    5.1.2 模型参数
- answers: '-   通过了解不同模型的特点和适用范围，可以确定哪个模型适合处理不同类型的图像。例如，v4模型适用于抽象图像和景观图像，而niji模型则适用于漫画风格图像。

    -   早期模型中的一些参数如--chaos和--quality对生成图像有影响。--chaos参数影响初始图像网格的变化程度，高值会产生更不寻常和意想不到的结果，低值则具有更可靠、可重复的结果。--quality参数影响生成图像所花费的时间和细节程度，高值会产生更多细节，但不一定总是更好。

    -   使用比例参数（--ar）可以改变生成图像的形状和组成。比如，通过设置不同的纵横比，可以使图像呈现不同的宽高比，从而改变图像的形状。例如，使用--ar
    2:3可以生成长方形的图像，而--ar 1:1则可以生成正方形的图像。

    -   稳定参数（--chaos）影响生成图像的结果。高值会产生更多不寻常和意想不到的结果，低值则会产生更可靠、可重复的结果。高值可能会使图像更具创意和多样性，而低值则可能更适合需要稳定结果的场景。

    -   Test模型和Testp模型的区别在于，Testp模型经过修改使其更具多样性和创造性。它们可以通过Version参数进行选择，例如，使用--v参数指定1或2或3或4或5来选择不同版本的模型。'
  questions: '-   如何确定哪个模型适合处理不同类型的图像？

    -   早期模型中的哪些参数对生成图像有影响？它们是如何影响的？

    -   如何使用比例参数（--ar）来改变生成图像的形状和组成？可以提供一些示例吗？

    -   稳定参数（--chaos）如何影响生成图像的结果？高值和低值分别会产生怎样的效果？

    -   Test模型和Testp模型有什么区别？它们分别是如何使用Version参数的？'
  summary: "-   Midjourney 定期发布新的模型版本以提高效率、一致性和质量。不同的模型擅长不同类型的图像。\n    1.  Niji--niji是可选的漫画风格模型。\n\
    \    2.  High Definition--hd是早期的模型之一，适用于抽象图像和景观图像。\n    3.  Test--test和Testp--testp使用test模型，Version--version可选择1至5模型。\n\
    -   其他参数只在早期的一些模型中生效，包括Creative、Image Weight、Sameseed和Video。\n    1.  Creative修改test和testp模型，使其更具多样性和创造性。\n\
    \    2.  Image Weight设置图像提示权重相对于文本权重，默认值是0.25。\n    3.  Sameseed种子值创建一个大的随机噪声场，应用于初始网格中的所有图像。\n\
    -   比例参数（--ar）--aspect或--ar参数改变生成图像的纵横比，影响生成图像的形状和组成。\n    1.  长宽比是图像的宽高比，可以是整数，如--ar\
    \ 139:100。\n    2.  纵横比范围影响生成图像的形状和组成。\n    3.  在描述词后加上相应的后缀即可使用，如--ar 2:3。\n\
    -   稳定参数（--chaos）--chaos或--c参数影响初始图像网格的变化程度，高值产生更多不寻常和意想不到的结果。\n    1.  低chaos值具有更可靠、可重复的结果。\n\
    \    2.  默认值为0，可变范围为0~100。"
  text: Midjourney 定期发布新的模型版本以提高效率、一致性和质量。不同的模型擅长不同类型的图像。#### 5.1.2.1 Niji--niji可选的漫画风格模型####
    5.1.2.2 High Definition--hd早期的模型之一，可以生成更大、不太一致的图像。该算法适用于抽象图像和景观图像。#### 5.1.2.3
    Test--test使用 test 模型，介绍见本文3.1模型章节#### 5.1.2.4 Testp--testp使用 test 模型，介绍见本文3.1模型章节####
    5.1.2.5 Version--version <1, 2, 3, 4, or 5> or --v <1, 2, 3, 4, or 5>使用 1 或 2
    或 3 或 4 或 5 模型，介绍见本文3.1模型章节目前默认是 4 模型#### 5.1.3 其他参数这些参数只在早期的一些模型中生效#### 5.1.3.1
    Creative--creative修改 test 和 testp 模型，使其更具多样性和创造性。#### 5.1.3.2 Image Weight--iw设置图像提示权重相对于文本权重，默认值是
    --iw 0.25.详情见本文6.1.3#### 5.1.3.3 Sameseed--sameseed种子值创建一个大的随机噪声场，应用于初始网格中的所有图像。当指定
    --sameseed 值时，初始网格中的所有图像都使用相同的起始噪声，并将生成非常相似的生成图像。#### 5.1.3.4 Video--video保存正在生成的
    4 张图像的进度视频。发送✉️时，会同步生成一个视频并发送。#### 不同模型，与可使用的参数，以及参数可变范围一览表![](img/f4762d97455f5541feaa7a97b7cb732e.png)###
    5.2 比例参数（--ar）--aspect 或 --ar 参数改变生成图像的纵横比。长宽比是图像的宽高比，它通常表示为用冒号分隔的两个数字，例如 7:4
    或 4:3 一类。正方形图像具有相等的宽度和高度，称为 1:1 的长宽比。图像可以是 1000px × 1000px，或者 1500px × 1500px，纵横比仍然是
    1:1默认长宽比为 1:1。必须使用整数，比如，用 --ar 139:100 而不是 --ar 1.39:1纵横比影响生成图像的形状和组成。当分辨率扩大时，一些纵横比可能会略有改变5.2.1
    不同模型纵横比范围表格![](img/2092ae784942d3a4dc95368e958d6789.png)5.2.2 一图直观了解纵横比![](img/619ce017e64a15befc3dcdaf702dd3c8.png)5.2.3
    如何使用在描述词后，加上相应的后缀即可，比如 --ar 2:3![](img/af97fd8153f7e299be31666a2fa63075.png)###
    5.3 稳定参数（--chaos）--chaos 或 --c 参数影响初始图像网格的变化程度。高 chaos 值将产生更多不寻常和意想不到的结果和组成。低
    chaos 值具有更可靠、可重复的结果。默认值为 0，可变范围为 0 ~ 100--chao 24示例：watermelon owl hybrid（西瓜猫头鹰杂合）5.3.1
    低 chaos 数值演示![](img/3fd08bda3c9299c11e912bf3f83ba03c.png)
- answers: '-   如何演示高 chaos 数值？

    -   若要演示高 chaos 数值，可以通过设置较高的 --chaos 或 --c 参数值来实现。这将导致初始图像网格的变化程度增加，从而产生更多不寻常和意想不到的结果和组成。

    -   在使用 chaos 或 c 参数时，有哪些注意事项需要考虑？

    -   在使用 chaos 或 c 参数时，需要考虑以下几点注意事项：

    -   如何演示超高 chaos 数值？

    -   要演示超高 chaos 数值，可以进一步提高 --chaos 或 --c 参数的数值，使其接近或达到其可变范围的上限。这将使初始图像网格的变化更加极端，产生极具不寻常性的结果和组成。

    -   如何通过改变质量参数 (--q) 来影响生成图像的时间？

    -   通过改变质量参数 (--q)，可以影响生成图像所花费的时间。具体而言，增加质量参数值将增加处理和生成图像所需的时间，因为高质量设置需要更多时间来处理和产生更多的细节。相反，降低质量参数值则会减少生成图像所需的时间。

    -   高质量不一定更好，那么如何在生成图像时平衡质量和效率？

    -   在生成图像时平衡质量和效率的关键是根据具体需求和预期结果来选择合适的质量参数值。有时候，低质量的设置可能会产生更好的效果，特别是在需要抽象表现或对生成时间有限制的情况下。因此，建议尝试不同的质量参数值，并根据实际情况选择最匹配的设置，以达到质量和效率的平衡。'
  questions: '-   如何演示高 chaos 数值？

    -   在使用 chaos 或 c 参数时，有哪些注意事项需要考虑？

    -   如何演示超高 chaos 数值？

    -   如何通过改变质量参数 (--q) 来影响生成图像的时间？

    -   高质量不一定更好，那么如何在生成图像时平衡质量和效率？'
  summary: "-   高 chaos 数值演示\n    1.  演示高 chaos 数值\n    2.  使用 chaos 或 c 参数\n    3.\
    \  超高 chaos 数值演示\n-   质量参数 (--q)\n    1.  改变生成图像时间\n    2.  高质量不一定更好\n    3. \
    \ v4 版本木森林测试\n-   种子参数 (--seed 和 --sameseed)\n    1.  种子号创建视觉噪声场\n    2.  使用相同种子号产生相似结果\n\
    \    3.  随机种子值生成不同图像"
  text: '![](img/ba5289969f838861e15670d801fb4433.png)5.3.2 高 chaos 数值演示![](img/213f4dddfda37b0182a65c1b96e4e78a.png)![](img/7ec7703b2f3e869295b2231281cb1582.png)5.3.3
    超高 chaos 数值演示![](img/9ec536a3d1495ab703cbdbbd01c4d16a.png)![](img/1c6f3533a2b825c780c5593f5fa5fbf5.png)5.3.4
    如何使用 chaos 值--chaos 或 --c 都可以![](img/92b76ed93a37a4803a708adf6c3d9988.png)###
    5.4 质量参数（--q）--quality 或 --q 参数改变生成图像所花费的时间。高质量的设置需要更长的时间来处理和产生更多的细节。更高的值还意味着每个作业使用更多的
    GPU 分钟，质量设置不影响分辨率。高质量的设置并不总是更好。有时候，低质量的设置可以产生更好的效果，这取决于你想要创建的图像。低质量的设置可能是最好的手势抽象表现。高质量的值可以改善建筑图像的表现，这与细节有关。试一试，并选择最匹配的设置。5.4.1
    v4 版本的木森林测试![](img/e7da72222ea86ea77204d1976db3fef0.png)![](img/41254a198d88e68071a81359cbdfac1e.png)5.4.2
    v5 版本的牡丹花测试![](img/6bc9cadb196d3fd18716fdf0a34eedb9.png)5.4.3 模型与参数兼容性测试![](img/0fa98e558db8cb57c23682ff3740b85b.png)5.4.4
    如何使用使用方式一，聊天框后缀--q 0.25--q 0.5--q 1--q 2![](img/5ffb6a05c85d7e3c158ceea213b59839.png)使用方式二/settings
    命令，设置默认值Half，Base，High quality![](img/fce1591979acd444f2e055f35a802f2c.png)👇![](img/13b3d2ba63317ee9ea23af02b2310a41.png)###
    5.5 种子参数（--seed 和 --sameseed）Midjourney 机器人使用一个种子号来创建一个视觉噪声场，就像电视静态一样，作为生成初始图像网格的起点。种子号是为每个图像随机生成的，但可以使用
    --seed 或 --sameseed 参数指定。使用相同的种子号和提示符将产生类似的结果图像。--seed 接受整数 0 - 4294967295。种子值只影响初始图像网格。模型版本
    1、2、3、test 和 testp是不确定的，将产生相似的，不相同的图像。模型版本 4、5 和 niji 中使用相同的“prompt + seed + 参数”将生成相同的图像。示例：celadon
    owl pitcher（青瓷猫头鹰水罐）5.5.1 随机种子值即使其他参数完全一致，生成的图像也不同![](img/295afdbba36ed494e7d25385b2c9c626.png)![](img/45ef68760187e8dc2864ead1ad97e1ad.png)可以看到，3
    次生成结果相差很大5.5.2 固定种子值比如，固定为 --seed 123，'
- answers: '-   在所有参数不变的情况下，区分 `seed` 和 `sameseed` 的关键在于生成的图像。当使用 `seed` 参数时，每次生成的图像都会有所不同，即使其他参数相同。而使用
    `sameseed` 参数时，所有生成的图像都会遵循同一个初始生成，即产生相似的结果图像。

    -   要找到适合生成特定图像的种子值，可以尝试不同的种子值并观察生成的图像效果。通常情况下，可以通过观察图像的细节、色彩和整体风格来判断种子值是否适合。

    -   在聊天框中添加种子值后缀的方法是在生成命令后面加上 `--seed [种子值]`，其中 `[种子值]` 是你想要使用的具体种子值。

    -   使用 `--stop` 参数提前中止图像生成工作的方法是在生成命令后面加上 `--stop [停止百分比]`，其中 `[停止百分比]` 是你想要提前中止生成的百分比值，范围是
    10 到 100。

    -   在停止参数的进阶用法中，影响最终放大结果的细节级别的方法是通过控制初始图像的停止点。如果初始图像停在一个更柔和、更不详细的状态，那么最终放大结果的细节级别会受到影响，导致更模糊、更不详细的结果。'
  questions: '-   在所有参数不变的情况下，如何区分 `seed` 和 `sameseed`？

    -   如何找到适合生成特定图像的种子值？

    -   使用种子值时，如何在聊天框中添加后缀？

    -   如何使用 `--stop` 参数提前中止图像生成工作？

    -   在停止参数的进阶用法中，如何影响最终放大结果的细节级别？'
  summary: "-   所有参数不变的情况下，生成的图像都一模一样（仅 v4,v5,niji 模型生效）\n    1.  sameseed 与 seed\
    \ 的区别：seed 只有第 1 张图遵循初始生成，sameseed 是全部 4 张图遵循初始生成\n    2.  如何寻找种子值：在对应的图像上添加✉反应，参照本文\
    \ 4.4.4 章节\n    3.  使用种子值在聊天框加后缀：比如 --seed 12345\n-   停止参数（--seed 和 --sameseed）使用\
    \ --stop 参数，提前中止图像生成工作\n    1.  基础用法\n    2.  进阶用法：影响最终放大结果的细节级别\n    3.  如何使用\
    \ Stop 值在聊天框加后缀：比如 --stop 90\n-   风格参数（--stylize 或 --s）Midjourney Bot 经过训练，可以生成具有艺术色彩、构图和形式的图像\n\
    \    1.  风格参数在不同的模型中，默认值与可变范围\n    2.  风格参数在 v4 模型的效果演示\n    3.  风格参数在 v5 模型的效果演示"
  text: 所有参数不变的情况下，无论多少次，生成的图像都一模一样（一模一样这个特性，仅 v4,v5,niji 模型生效）![](img/a90600f1a4c713d64beee680c425afc2.png)5.5.3
    sameseed 与 seed 的区别区别就是seed 只有第 1 张图遵循初始生成sameseed 是全部 4 张图遵循初始生成--sameseed 数值范围
    0 - 4294967295--sameseed 只兼容模型版本 1，2，3，test 和 testp固定 sameseed 前后生成对比![](img/b07940c131aacf6761aefc9cc8caa263.png)固定
    seed 前后生成对比![](img/8520fe390b7fe91b646a21f12d9ff687.png)5.5.4 如何寻找种子值在对应的图像上，添加✉反应，参照本文
    4.4.4 章节![](img/6a6697ab3b3ebba9cda0d652c5d0a797.png)5.5.5 使用种子值在聊天框加后缀比如：--seed
    12345![](img/769af08df040d83229686e3e95c8d4f4.png)### 5.6 停止参数（--seed 和 --sameseed）使用
    --stop 参数，提前中止图像生成工作，以较早的百分比停止，可能会产生更模糊、更不详细的结果。--stop 的默认值 100--stop 可变范围 10-100--stop
    在图像放大时不起作用举例：splatter art painting of acorns（橡子飞溅艺术画）5.6.1 基础用法![](img/e7b860ee1e2df0d68b9358f374ce4aa0.png)![](img/931487c0f7a1b85d7cad4ca982e255ee.png)5.6.2
    进阶用法--stop 参数虽然在图像放大时没有作用。但是，如果初始图像停在一个更柔和，更不详细的初始图像上，会将影响最终放大结果的细节级别。下面放大的图片使用的是
    Beta Upscale![](img/9660249e7845023a12bbe14099c823a4.png)5.6.3 如何使用 Stop 值在聊天框加后缀比如：--stop
    90![](img/9e5782647f2937b3fd8b316433539444.png)### 5.7 风格参数（--stylize 或 --s）Midjourney
    Bot 经过训练，可以生成具有艺术色彩、构图和形式的图像。--stylize 或 --s 参数影响该训练的应用强度。低风格化值生成的图像与提示符紧密匹配，但不太具有艺术性。高风格化值创建的图像非常艺术，但与提示符联系较少。5.7.1
    风格参数在不同的模型中，默认值与可变范围![](img/6c2d3cce753f8e46d1564b6acab81b95.png)5.7.2 风格参数在 v4
    模型的效果演示illustrated figs（无花果插图）![](img/f2d389be9ea754dec6fd813229d13296.png)![](img/7dcd67d9127d3ac277707111cc286280.png)5.7.3
    风格参数在 v5 模型的效果演示colorful risograph of a fig（无花果的彩色等线图）![](img/a7fdb214607801f608dddc37695ebf7a.png)
- answers: '-   如何使用风格参数：使用方式一，在聊天框后缀加入 --s 参数，后接风格化值；使用方式二，通过/settings命令，选择默认的风格参数。

    -   平铺参数（--tile）：平铺参数用于生成可重复使用的图像，适用于模型版本1、2、3和5。

    -   版本参数（--v）：版本参数用于选择使用的模型版本，可通过 --v 参数或 --version 参数后接模型版本数字来指定。可选值为1、2、3、4和5。

    -   使用风格参数时的两种方式是什么？：一种是在聊天框后缀加入 --s 参数后接风格化值，另一种是通过/settings命令设置默认的风格参数。

    -   平铺参数用于什么目的？它支持哪些模型版本？：平铺参数用于生成可用于重复瓷砖的图像，支持模型版本1、2、3和5。

    -   版本参数的作用是什么？它有哪些可选值？：版本参数用于选择使用的模型版本，可选值包括1、2、3、4和5，不同版本擅长处理不同类型的图像。

    -   如何设置聊天框后缀以使用风格参数？：通过在聊天框后缀中加入 --s 参数后接风格化值来设置聊天框后缀以使用风格参数。

    -   通过/settings命令如何设置风格参数的默认值？：通过/settings命令选择默认的风格参数，可选值包括Style low、Style med、Style
    high、Style very high。'
  questions: '-   如何使用风格参数

    -   平铺参数（--tile）

    -   版本参数（--v）

    -   使用风格参数时的两种方式是什么？

    -   平铺参数用于什么目的？它支持哪些模型版本？

    -   版本参数的作用是什么？它有哪些可选值？

    -   如何设置聊天框后缀以使用风格参数？

    -   通过/settings命令如何设置风格参数的默认值？'
  summary: "-   如何使用风格参数\n    1.  使用方式一，设置聊天框后缀\n    2.  使用方式二，通过/settings命令设置默认值\n\
    \    3.  可选的风格参数有low、med、high、very high\n-   平铺参数（--tile）\n    1.  生成可用于重复瓷砖的图像\n\
    \    2.  适用于模型版本1，2，3和5\n    3.  可使用图案制作工具生成多平铺图\n-   版本参数（--v）\n    1.  定期发布新的模型版本以提高效率、一致性和质量\n\
    \    2.  默认为最新模型，但测试版除外\n    3.  可选的版本参数有1、2、3、4和5"
  text: 5.7.4 如何使用风格参数使用方式一，聊天框后缀比如--s 1000![](img/6e103fc9b6f3f28db918454301a71974.png)使用方式二/settings
    命令，设置默认值Style low，Style med，Style high，Style very high![](img/fce1591979acd444f2e055f35a802f2c.png)👇![](img/4a2f7db598d4f58ef06a0e7d9e8a3114.png)###
    5.8 平铺参数（--tile）tile 参数生成的图像可用于重复瓷砖，为织物、壁纸和纹理创建无缝图案。--tile 适用于模型版本 1，2，3 和 5--tile
    只生成一个贴图使用图案制作工具，如 [https://www.pycheung.com/checker/](https://www.pycheung.com/checker/)，可以产生多平铺图5.8.1
    平铺参数在 test 和 testp 模型的效果演示colorful tiger stripes（彩色虎纹）torn cardboard roses（破碎的纸板玫瑰）![](img/44da4138b2c07f4e50256a257032ae38.png)5.8.2
    平铺参数在 v5 模型的效果演示scribble of moss on rocks（在岩石上画苔藓）watercolor koi（水彩锦鲤）![](img/953307b3fb9a9fa713edef07288bcf99.png)5.8.3
    如何使用平铺参数使用方式一，聊天框后缀，加入 --tile![](img/abb54174a820eaa3316adadd7fde63b5.png)###
    5.9 版本参数（--v）Midjourney 定期发布新的模型版本以提高效率、一致性和质量。一般默认为最新模型，但测试版的除外，比如虽然现在 v5 发布了，但它是测试版。所以目前默认还是
    v4其他模型也可以使用，用 --version 或 --v 参数，或使用/settings 命令并选择一个模型版本。不同的模型擅长不同类型的图像。--version
    的可选项：1、2、3、4 和 5。--version 也可以是 --v ，效果等同比如：--v 5模型对比，已经展示过，在本文的3.1章节，可以看不同模型的对比5.9.1
    如何使用模型参数使用方式，聊天框后缀，加入 --v 参数+模型版本数字比如， --v 4![](img/45f707826c74407fc028a853f717f671.png)###
    5.10 视频参数（--video）保存正在生成的 4 张图像的进度视频。发送✉️时，会同步生成一个视频并发送。视频只能在 4 张初始图生成时的视频，不能放大。视频目前，只在模型版本
    1，2，3，test，和 testp 中有用5.10.1 视频参数的效果演示Vibrant California Poppies（充满活力的加州花）![](img/1f2c1353cb4ab34823c50a161380df7f.png)Botanical
    Sketch of Fanciful Ferns（奇异蕨类植物素描）![](img/a11dc60a531d42d6039b7edd2867d23f.png)5.10.2
    怎么样获得上述视频1\. 在描述词结尾添加 --video 作为后缀2\. 等待图像生成完毕3\. 在对应图片的记录添加信封反应，
- answers: '-   如何使用图像提示影响画面结构、样式和颜色？

    -   图像提示可以与文本提示一起使用吗？这样做会有什么效果？

    -   什么是基础操作，包括上传图像、将图像拖入聊天框、写描述词和参数，然后生成图片？

    -   v4和v5模型示例如何展示了不同素材的融合？

    -   v3模型的图像提示如何更抽象？如何使用图像权重参数调整图像影响？

    -   使用图像提示可以通过将图像作为提示符的一部分来影响画面的结构、样式和颜色。这种方法可以单独使用，也可以与文本提示结合使用，产生不同的效果。

    -   是的，图像提示可以与文本提示一起使用。这样做可以将不同风格的图像与文本结合，产生更加丰富和神奇的效果。

    -   基础操作包括上传一张图像，在出图时将图像拖入聊天框，然后在链接后写入后续的描述词和参数，最后点击发送以生成图片。

    -   v4和v5模型示例展示了不同素材的融合，通过将不同的图像素材组合在一起，如雕像、花卉、水母等，生成具有不同风格的图像。

    -   v3模型的图像提示更加抽象，被用作视觉灵感而不是作为生成图像的起点。可以使用图像权重参数调整图像影响，数值越大，上传的图像对生成图像的影响就越大。'
  questions: '-   如何使用图像提示影响画面结构、样式和颜色？

    -   图像提示可以与文本提示一起使用吗？这样做会有什么效果？

    -   什么是基础操作，包括上传图像、将图像拖入聊天框、写描述词和参数，然后生成图片？

    -   v4和v5模型示例如何展示了不同素材的融合？

    -   v3模型的图像提示如何更抽象？如何使用图像权重参数调整图像影响？'
  summary: "-   进阶描述词可以通过图像提示影响画面结构、样式和颜色，高级提示词包括图像url、文本短语和参数。\n    1.  图像提示可单独或与文本提示一起使用，组合不同风格的图像会产生神奇效果。\n\
    \    2.  基础操作包括上传图像、将图像拖入聊天框、写描述词和参数，然后生成图片。\n    3.  v4和v5模型示例展示了不同素材融合，v3模型的图像提示更抽象，可使用图像权重参数调整图像影响。"
  text: 操作同本文 4.4.4 章节![](img/5bbf5aa65de812497b945eaaacb25849.png)4\. 得到下载链接![](img/c2810a8f80b2a3aac308684403c9e79e.png)##
    六、进阶描述词### 6.1 图生图进阶可以将图像作为提示符的一部分来影响画面的结构、样式和颜色。图像提示可以单独使用，也可以与文本提示一起使用将不同风格的图像组合在一起，会获得神奇的效果更高级的提示词可以包括一个或多个图像
    url、多个文本短语和一个或多个参数![](img/d0c373e26d846938a2f1f2b0c8de1afb.png)6.1.1 基础操作1\. 上传一张图2\.
    在出图时，跳出 prompt 聊天框后，直接将上传好的图拖动入聊天框，这样，描述词就出现了上述绿色部分的链接。（可以不止上传一个参考图，可以上传多个）3\.
    在链接后，写后续的描述词和参数即可4\. 写完，点击发送，开始生成图片![](img/9b7f78ed8b432f53e31e6d365a576e3e.png)6.1.2
    v4 模型和 v5 模型示例仅作展示用，个人觉得下面这些案例并不是很好看，但也看过很好看的，这个功能还是很强的。这两个新模型的图生图，图像是作为生图的起点，所以在结构、配色、构成上，都会更接近图片。同样，有时候会看上去很牵强，各有利弊。####
    6.1.2.1 基础图片素材① 阿波罗雕像② 复古花卉插图③ 恩斯特·海克尔的水母④ 恩斯特·海克尔的地衣⑤ 北斋的《巨浪》![](img/685a97f153a8c4631689b448e48591d9.png)####
    6.1.2.2 v4 模型的素材融合① 雕像 + 花② 雕像 + 水母![](img/60b950ba6ac9b4c2ea88fe936578a45e.png)③
    雕像 + 苔藓④ 雕像 + 波浪![](img/2499d98ace3ccb81c3fe3ea37eafb3df.png)⑤ 雕像 + 苔藓 + 花![](img/f41abe33dc5e03c048d0f461b94e73eb.png)####
    6.1.2.2 v5 模型的素材融合① 雕像 + 花② 雕像 + 水母![](img/f25d0f6718436e750619f3645dab40ea.png)③
    雕像 + 苔藓④ 雕像 + 波浪![](img/f76595b0552c5d087b165fba6b6213f9.png)⑤ 雕像 + 苔藓 + 花![](img/9480fc8a687fab279c677db6b992f82b.png)6.1.3
    v3 模型的示例早期，模型版本的图像提示比目前的模型更加抽象。图像提示被用作视觉灵感，而不是作为起点。这一点，我个人非常喜欢。有一个概念，叫做图片的权重，数值越高，参考图片的影响就越大####
    Image Weight  👉 --iw--iw 图像的权重早期的 Midjourney 模型版本可以使用图像权重参数 --iw 来调整图像 url，--iw
    0.25 是默认值，可变范围为 -10000 ~ 10000数值越大，则意味着上传的图像会有更大的影响。举个例子：描述词： [http://kandinsky.png](http://kandinsky.png)
    vibrant California poppies --v 3 --iw <value>上传图像与描述词不变的情况下，改变 --iw 后的数值，对图像造成的影响👇
- answers: '-   在Remix模式中，可以通过添加或删除参数来修改图像参数。参数的范围取决于具体的参数类型，但通常在可变范围区间内进行调整。

    -   使用Remix模式时，可以通过两种方式打开：一种是在聊天框中调用命令`/prefer remix`，另一种是通过`/settings`命令，在设置中将Remix模式切换为启用状态。

    -   在Remix效果展示中，可以生成新图像的方法是首先点击“Make Variations”按钮，然后根据需要修改描述词、模型词或其他参数，并提交以开始生成新图像。

    -   若要修改Remix搭配的参数，可以添加或删除参数，但是这些参数必须能够在语义上匹配。参数的范围和匹配要求取决于具体的参数类型，一般来说，可以参考之前的参数模型匹配表来了解参数的影响范围和匹配要求。

    -   复杂提示词可以使用双冒号(::)作为分隔符，将提示符分隔为不同的部分，每个部分可以独立分配权重。这样可以独立考虑每个单词部分的影响，从而生成不同风格的图像。'
  questions: '-   在Remix模式中，如何修改图像参数？

    -   使用Remix模式时，如何打开该模式？

    -   在Remix效果展示中，如何生成新图像？

    -   如何修改Remix搭配的参数？它们的范围和匹配要求是什么？

    -   复杂提示词如何使用？它们的格式和作用是什么？'
  summary: "-   图像处理参数修改\n    1.  使用Remix模式改变图像参数\n    2.  可以通过命令或设置打开Remix模式\n  \
    \  3.  修改描述词、模型词或主题实现图像变化\n-   Remix效果展示\n    1.  涉及V1，V2，V3，V4和Make Variations按钮\n\
    \    2.  点击Make Variations，修改描述词生成新图像\n    3.  添加--test修改模型参数，修改主题和绘图媒介\n-   Remix搭配参数修改\n\
    \    1.  可以添加或删除参数，但必须匹配\n    2.  参数需在可变范围内\n    3.  适用范围需符合参数模型匹配表中的影响范围\n- \
    \  复杂提示词\n    1.  使用::分隔符考虑多个独立概念\n    2.  Midjourney Bot可以使用多样提示词基础\n    3. \
    \ 提示词可以分别考虑不同概念"
  text: '最左上角为上传的参考图![](img/3e0fc05ab2d925d7bb1c76eb0e88b169.png)描述词 2： [http://sunflowers.png](http://sunflowers.png)
    vibrant California poppies --v 3 --iw <value>上传图像与描述词不变的情况下，改变 --iw 后的数值，对图像造成的影响👇最左上角为上传的参考图![](img/91148ce39100d99277ed2d844af49c27.png)###
    6.2 修图重要参数（Remix）使用 Remix 模式更改提示符、参数、模型版本或其他参数。Remix 将采用初始图像的一般组成，并将其用作新 Job 的一部分。Remix
    可以帮助改变图像的设置或光影，演变主题，或实现棘手的构图。Remix 是一个实验性的参数，有可能随时更改或删除，目前可以用。6.2.1 Remix 开关打开方式一：聊天框调用命令
    /prefer remix![](img/33a09ee227cab44c4df3ef851af752f7.png)打开方式二：/settings 命令，设置默认值Remix
    mode![](img/fce1591979acd444f2e055f35a802f2c.png)👇![](img/ba5df290e532d3c7ffa0ee0813ad5192.png)点一下，变成绿色，就启用了6.2.2
    Remix 效果展示######## 6.2.2.1 概括介绍涉及 V1，V2，V3，V4，以及 Make Variations 的按钮，都会先跳出一个文本框，在原有文本的基础上作修改![](img/05fb209b1f689271e7179ef8c402be6e.png)![](img/f3f189d78bf775ba6d463853afbed97b.png)####
    6.2.2.2 实际展示-修改内容词![](img/8ebe0d5775c2513d67b219e295b6bb01.png)① 点一下 Make Variations②
    修改描述词为“pile of cartoon owls”（一堆卡通猫头鹰）③ 点“Submit”，开始生成，在原图的基础结构上，出现一堆猫头鹰👇![](img/e0b4c03b696d4c91ea8f9945060b7adb.png)6.2.2.3
    实际展示-修改模型词其他过程不变，最后输入词汇时，添加 --test (相当于补充修改了模型参数)![](img/45b48d5445fcf7e650e495f13b1010b5.png)6.2.2.3
    实际展示-修改主题，修改绘图媒介![](img/a61c63ef482f5ef9246150e92e81baba.png)6.2.3 Remix 搭配参数修改可以添加或者删除参数，但是参数之间必须要能契合搭配，数值在可变范围区间之内。参照之前的参数模型匹配表在对应影响范围内的参数才能工作左边一列，是初始生成的影响参数（也就是产生
    4 张小图）右边一列，是影响变化的影响参数（也就是放大分辨率，以及变化等操作）同样，Remix 修改的适用范围也在这里![](img/a9241b6c7dcede50d5aebd1bac10bceb.png)###
    6.3 复杂提示词（多样 prompt）6.3.1 多样提示词基础Midjourney Bot 可以使用 :: 作为分隔符，分别考虑两个或多个独立的概念。'
- answers: '-   分离提示符的两种独立分配权重的方式是使用双冒号(::)分隔。第一种方式是在双冒号后添加数字权重，这会影响单词部分的相对重要性。例如，使用"hot::2
    dog"，将使单词"hot"的权重比"dog"重要两倍，导致生成一个非常热的狗的图像。第二种方式是通过将某些词的权重调为负数来去除不想要的元素。例如，使用"--no"参数加上不想要的词，等同于将其权重调为负数，这样就可以去除不需要的元素，例如"vibrant
    tulip fields --no red"。

    -   通过评分可以获取免费出图时长。排名前1000的评分者每天可以获得一小时的免费Fast模式时间。

    -   描述词的权重影响图像生成的效果是通过调整单词部分的相对重要性来改变生成图像的特征。负向描述词的作用是去除不想要的元素，通过将其权重调为负数来降低其在生成图像中的影响。

    -   社区Rank部分与高评分图片相关，评级高的图片会出现在该部分。最高评分者会在获得小时数时收到来自Midjourney Bot机器人的赠送时长消息。

    -   分离提示符分为一部分时，会生成将所有单词部分放在一起考虑的图像，而分为两部分时，则会分别考虑每个单词部分，生成与两个概念相关的图像。'
  questions: '-   什么是分离提示符的两种独立分配权重的方式，它们分别如何影响图像生成？

    -   如何通过评分来获取免费出图时长？排名前1000的评分者每天可以获得多少免费Fast模式时间？

    -   描述词的权重和负向描述词如何影响图像生成效果？

    -   社区Rank部分如何与高评分图片相关？最高评分者如何收到赠送时长消息？

    -   分离提示符分为一部分和两部分时，分别会生成什么样的图像？'
  summary: "-   分离提示符可以独立分配每个单词部分的权重，生成不同图像。\n    1.  提示符分为一部分时，考虑所有单词，生成相关图像。\n \
    \   2.  提示符分为两部分时，分别考虑每个概念，生成不同图像。\n    3.  描述词权重和负向描述词可影响图像生成效果。\n-   获得免费出图时长的方法。\n\
    \    1.  通过评分赚取免费出图时长。\n    2.  排名前1000的评分者每天可获得一小时免费Fast模式时间。\n    3.  高评分图片会出现在社区Rank部分，最高评分者可获得赠送时长消息。"
  text: '分离提示符可以独立分配每个单词部分的权重，也就是多生成或少生成一点。在下面的例子中，对于提示“hot dog”，所有的单词都被放在一起考虑，Midjourney
    Bot 会生成美味热狗的图像。如果提示符分为两部分，则分别考虑“hot:: dog”这两个概念，创建一个温暖的狗的图片。双冒号之间没有空格 ::多提示符适用于模型版本
    1，2，3，4 和 niji![](img/c53252a64581d7385102f1909cabb332.png)（左图）杯子蛋糕插图被认为是一起的，出现了杯子蛋糕的插图图像。（右图）杯子和蛋糕插图是分开考虑的，蛋糕的图像是放在杯子里的。![](img/cbbd19745eac44e6d60c1ef6b4365b48.png)杯子、蛋糕和插图分别考虑，在杯子中制作一个蛋糕，其中有常见的插图元素，如花和蝴蝶。![](img/f31e5c7c059a83f407e180e042db992e.png)6.3.2
    描述词权重当使用双冒号 :: 将提示符分隔为不同的部分时，可以在双冒号后立即添加一个数字，以分配提示符该部分的相对重要性。模型 1,2,3 只接受整数作为权重（比如::2）模型
    4 可以接受小数权重（比如::1.2）未指定的权重默认为 1在下面的例子中，提示符 hot:: dog 生成了一条热的狗。将提示符更改为 hot::2 dog
    会使单词 hot 比单词 dog 重要两倍，从而产生一个非常热的狗的图像!![](img/68883cec42a43d8a9fbd8b7e6a301f06.png)注意：权重只与相对比有关，与具体数值无关，比如，权重为
    2 的 hot 加权重为 1 的 dog，与权重为 100 的 hot 加权重为 50 的 dog，效果是等同的6.3.3 负向描述词不想要的元素，可以去除通过将权重调为负数实现下图，红色被调成
    -0.5 的权重，因此，红色程度就降低了![](img/59ee5dd559ae2dfa2d809658bf6e2f90.png)6.3.4 --no 参数--no
    加上不想要的词，等同于将其权重调为 -0.5“vibrant tulip fields:: red::-.5”和“vibrant tulip fields
    --no red”在语义上是一样的## 七、获得免费出图时长你可能不知道，还可以用评分赚取免费出图时长！在任何地方，都可以通过点😊，选择你喜欢的图像![](img/ff8f11577e3c5df12580a16932166615.png)每天，排名前
    1000 的图像评分者可以获得一小时的免费 Fast 模式时间。评级高的图片会出现在社区 Rank 部分。如果你是当天的最高评分者之一，当你获得小时数时，就能收到来自
    Midjourney Bot 机器人的赠送时长消息。![](img/5192b779632f0c51aa78b575c2c273a7.png)Web 评分入口：[https://www.midjourney.com/app/ranking/](https://www.midjourney.com/app/ranking/)如果足够幸运，就能得到免费时长👇![](img/195d5c74dbed80679a7931fc271921f6.png)好啦，关于
    Midjourney，基础的介绍大概就到这里啦。评论区：一 an 严 : 这个量，这个详细程度，强推加精[强] 北辰 : 赞～[玫瑰]学习了 气急败坏灰太狼
    : 大佬有没有做成飞书云链接，感觉好长，'
- answers: '-   网友点赞余锟的教程。

    -   Andy Weng称赞教程详细。

    -   网友期待详细操作步骤。

    -   天辉教练分享内容受赞扬。

    -   网友期待更多详细教程。

    -   网友强烈推荐并点赞。

    -   余锟的教程受到网友的点赞是因为它详细而有用。

    -   Andy Weng对于余锟的教程评价称其详细。

    -   网友期待的详细操作步骤包括更多细节和指导。

    -   天辉教练分享的内容受到赞扬，因为内容丰富、有价值。

    -   网友强烈推荐并点赞天辉教练的分享是因为内容受欢迎，可能解决了他们的问题或提供了有用的信息。'
  questions: "-   余锟的教程受到好评\n    1.  网友点赞余锟的教程\n    2.  Andy Weng称赞教程详细\n    3.  网友期待详细操作步骤\n\
    -   天辉教练分享受欢迎\n    1.  天辉教练分享内容受赞扬\n    2.  网友期待更多详细教程\n    3.  网友强烈推荐并点赞\n- \
    \  余锟的教程为何受到网友的点赞？\n-   Andy Weng对于余锟的教程有何评价？\n-   网友期待的详细操作步骤是什么？\n-   天辉教练分享的内容受到了怎样的赞扬？\n\
    -   为什么网友强烈推荐并点赞天辉教练的分享？"
  summary: "-   余锟的教程受到好评\n    1.  网友点赞余锟的教程\n    2.  Andy Weng称赞教程详细\n    3.  网友期待详细操作步骤\n\
    -   天辉教练分享受欢迎\n    1.  天辉教练分享内容受赞扬\n    2.  网友期待更多详细教程\n    3.  网友强烈推荐并点赞"
  text: '得多研究研究[奋斗][奋斗] 余锟 : 先点赞，再看[强] Andy Weng🍍 : [发呆]有幸见面会坐在大佬旁边，这么详细的教程，值得仔细拜读
    胡椒面 : 期待 sd 的详细操作[色] 琨儿 : 太赞了，天辉教练的分享也太详细了！ 那个雨的夜 : 强推加精+1[强]'
