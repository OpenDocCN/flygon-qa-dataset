- answers: '-   如何降低训练个性化大模型的成本？

    -   通过选择基于一个基础模型进行训练，采用 Fine-tuning（微调）或 Embedding（嵌入）的方式，往模型中添加自定义的个性化数据，从而降低成本。

    -   微调和嵌入训练个性化模型的方式有何异同？

    -   微调是在预训练模型的基础上，使用特定任务数据对模型进行重新训练，以适应具体的应用场景或任务；而嵌入是将高维的离散数据转化为低维连续向量表示的过程，捕捉单词之间的关联和语义相似性。

    -   个性化模型相比通用模型在特定任务上的优势体现在哪些方面？

    -   个性化模型可以更好地适应特定任务的需求，提高在该任务上的准确性和效果，因为它包含了特定领域或任务的个性化数据，具有更强的专业性和针对性。

    -   在选择微调或嵌入训练个性化模型时，应考虑哪些因素？

    -   应考虑任务的复杂度、可用的数据量和质量、训练时间、计算资源等因素。微调适用于任务数据充足的情况，而嵌入则适用于数据量较小或需要频繁更新的情况。

    -   个性化模型在应用于特定任务时，可能会遇到哪些挑战？

    -   可能会遇到数据稀缺、领域专业性不足、过拟合、性能评估困难等挑战。此外，还需要注意模型的泛化能力和对新数据的适应能力。'
  questions: '-   如何降低训练个性化大模型的成本？

    -   微调和嵌入训练个性化模型的方式有何异同？

    -   个性化模型相比通用模型在特定任务上的优势体现在哪些方面？

    -   在选择微调或嵌入训练个性化模型时，应考虑哪些因素？

    -   个性化模型在应用于特定任务时，可能会遇到哪些挑战？'
  summary: "-   从零开始：使用微调和嵌入训练自己的 AI 个性化大模型\n    1.  大模型训练成本高，但可以通过微调或嵌入训练个性化模型。\n\
    \    2.  微调和嵌入是训练个性化模型的两种方式。\n    3.  个性化模型可以提高模型在特定任务上的准确性和效果。"
  text: '# 从零开始：使用微调和嵌入训练自己的 AI 个性化大模型> 原文：[`www.yuque.com/for_lazy/thfiu8/cllfw39br1fqib3a`](https://www.yuque.com/for_lazy/thfiu8/cllfw39br1fqib3a)##
    (22 赞)从零开始：使用微调和嵌入训练自己的 AI 个性化大模型作者： 叫我峰兄日期：2023-10-10# 一.前言ChatGPT 是“大力出奇迹”的经典表现，大模型给
    ChatGPT 带来了惊人的智能，但是要训练这样的大模型，可是十分烧钱的，根据 OpenAI 给出的数据，1700 亿参数的 Davinci 模型从头训练一遍，大概需要耗时
    3 个月，耗资 150 万美元。那我们普通人或者小公司面对这个高门槛，对自定义模型是不是就完全没有希望了呢？其实除了从头训练一个模型，我们还可以选择基于一个基础模型进行训练，这样，我们可以往里添加自己的个性化数据，最终得到一个领域增强的个性化模型，目前有两种训练语料的方式
    embedding(嵌入)、Fine-tuning(微调)。个性化模型有什么用？我们知道，OpenAI 给的模型（如 Davinci、Curie、gpt3.5-turbo）都是通用化模型，而现代社会的行业和知识如此之庞大，每个领域都有自己细分的专业知识，比如，我们知道
    ChatGPT 的一个典型应用场景就是智能客服，但同样是客服，保险领域的客服和淘宝店铺的客服需要面对的客戶和需要解答的问题就完全不一样，想要给出更好的答案，我们就需要打磨自己的个性化模型。我们也可以用自己之前写的文章训练一个
    AI 版的自己，以个性化的口吻回复用户的问题。# 二.主流的训练模型的两种方式 Fine-tuning 和 Embedding## (一).概念介绍：1.  Fine-tuning（微调）：Fine-tuning
    是指在预训练模型的基础上，使用特定的任务数据对模型进行重新训练，以适应具体的应用场景或任务。通常，预训练模型通过大规模数据集进行事先训练，获得了广泛的语言理解和生成能力。而
    Fine-tuning 则是在此基础上，针对特定任务的数据集进行进一步训练，以使模型更好地适应该任务，并提高其性能。通过 Fine-tuning，可以使模型更加专业化，提高在具体任务上的准确性和效果。2.  Embedding（嵌入）：Embedding
    是将高维的离散数据转化为低维连续向量表示的过程。在自然语言处理中，Word Embedding 是一种常见的技术，将词汇表中的单词映射为实数向量。这些向量在低维空间中对应着单词的语义信息，使得计算机可以更好地理解和处理文本数据。通过将词汇嵌入到低维向量空间中，可以捕捉到单词之间的关联和语义相似性，从而使得模型能够更好地进行语言理解和相关任务。3.  在使用
    GPT 模型进行自然语言处理任务时，通常会先进行预训练得到一个通用的语言模型，然后根据具体的任务数据对模型进行 Fine-tuning，使其适应特定任务的需求。同时，模型将单词和文本嵌入到低维向量空间中，用于表示和处理文本数据，从而提高模型的语义理解能力和任务性能。Fine-tuning
    和 Embedding 可以共同帮助模型更好地适应特定任务，并提升模型在该任务上的表现。## （二）.Fine-tuning 和 Embedding 的区别1.  微调就像你通过学习准备考试，是一种长期记忆，但过了一周后考试来临，模型可能会忘记袭击，或者记错它从来没有读过的事实。'
- answers: '-   嵌入搜索方式有文本数量限制的具体限制是：GPT-3.5是4K（大约5页），GPT-4最大是32K（大约40页）。

    -   OpenAI建议的“搜索-问”方法是通过先在本地文档库中进行搜索，然后将搜索结果和问题一起交给GPT，以便GPT根据提供的内容和模型中的数据一起返回结果。

    -   GPT-3.5和GPT-4在文本处理能力上的主要区别是，GPT-4最大处理32K文本，而GPT-3.5最大处理4K文本。

    -   在处理32K文本时，GPT-4相比于GPT-3.5的优势是能够处理更大范围的文本数据。

    -   在利用GPT获取结果之前进行本地搜索的主要目的是为了结合本地数据和GPT模型中的数据，以获取更准确的结果。'
  questions: '-   嵌入搜索方式有文本数量限制的具体限制是什么？

    -   OpenAI建议的“搜索-问”方法是如何构建问答系统的？

    -   GPT-3.5和GPT-4在文本处理能力上的主要区别是什么？

    -   在处理32K文本时，GPT-4相比于GPT-3.5有哪些优势？

    -   在利用GPT获取结果之前进行本地搜索的主要目的是什么？'
  summary: "-   嵌入就像记笔记，是一种短期记忆，方便考试时查阅笔记。\n    1.  笔记带来准确答案。\n    2.  嵌入搜索方式有文本数量限制。\n\
    \    3.  OpenAI建议“搜索-问”方法构建问答系统。\n-   GPT-3.5和GPT-4的文本处理能力不同。\n    1.  GPT-3.5处理4K文本。\n\
    \    2.  GPT-4处理32K文本。\n    3.  建议本地搜索后再提问GPT获取结果。"
  text: '2.  嵌入就像记笔记，是一种短期记忆，当考试的时候，你把笔记带上，随时翻看笔记，对于笔记上有的内容可以得到准确的答案。3.  另外嵌入的搜索提问方式相对于微调有一个缺点就是它每次附带的文本数量是有限制的，因为除了原始的问题，它还需要带上搜索出来的问题，GPT-3.5
    是 4K（大约 5 页），GPT-4 最大是 32K（大约 40 页）。4.  就好比你有成书的教科书可以借鉴，但每次却只能翻看其中几页笔记。5.  如果你想构建一个对大量文本问答的系统，OpenAI
    建议“搜索-问”（Search-Ask）的方法。6.  也就是先在本地文档库中 Search，拿到本地的数据结果，再去 Ask，把搜索结果和问题一起交给 GPT，这样
    GPT 可以根据你提供的内容以及它模型中的数据，一起将结果返还给你。为了更好的阅读体验，请前往飞书链接阅读：[`l0lupq5bcjq.feishu.cn/docx/DUOjdFQ6UoF3S3xppyvcYNzPnh6`](https://l0lupq5bcjq.feishu.cn/docx/DUOjdFQ6UoF3S3xppyvcYNzPnh6)*
    * *评论区：melisa : 棒Yuti : 好详细，解释的也比较明白叫我峰兄 : 感谢支持，有帮助就好[呲牙]乔帮主 : 很详细的整理，赞👍叫我峰兄 :
    帮主是我见过的为数不多的既懂技术又懂业务的大佬，从乔哥身上学到很多，我会继续努力，追赶乔哥的脚步[加油]叫我峰兄 : 感谢支持![](img/1c37d505930596d12a88ab23e11aa07a.png)*
    * *'
